{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "20MAI1013-LAB04-ALEX_NET_fashion_mnist.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpZJw5Fjs3zX"
      },
      "source": [
        "**20MAI1013**     **fashion_mnist** **Dataset** **using** **AlexNet** **architecture** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cWJgsUEb_gP"
      },
      "source": [
        "#Keras library for CIFAR dataset\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "from keras.callbacks import History\n",
        "history = History()\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izrBez00dyjz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb11f708-a11b-4712-9b72-d7ee0e6fd8ac"
      },
      "source": [
        "(x_train, y_train),(x_test, y_test)=fashion_mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA84uQGCb_gR"
      },
      "source": [
        "#Train-validation-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NkSUizqG5Yl"
      },
      "source": [
        "x_train = x_train.reshape(-1,28,28,1)\r\n",
        "x_val = x_val.reshape(-1,28,28,1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVPA1gUXb_gY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef9e1380-b281-42c5-9608-fdb08eac43c6"
      },
      "source": [
        "#Dimension of the CIFAR10 dataset\n",
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "#print((x_test.shape,y_test.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((42000, 28, 28, 1), (42000,))\n",
            "((18000, 28, 28, 1), (18000,))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oGIARqcb_ga"
      },
      "source": [
        "#Onehot Encoding the labels.\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#Since we have 10 classes we should expect the shape[1] of y_train,y_val and y_test to change from 1 to 10\n",
        "y_train=to_categorical(y_train)\n",
        "y_val=to_categorical(y_val)\n",
        "#y_test=to_categorical(y_test)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMBwHCrEb_gb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f514bf49-5f93-4c18-9ccf-ec9a2cb3eac1"
      },
      "source": [
        "#Verifying the dimension after one hot encoding\n",
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "#print((x_test.shape,y_test.shape))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((42000, 28, 28, 1), (42000, 10))\n",
            "((18000, 28, 28, 1), (18000, 10))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9gc0vCDb_gc"
      },
      "source": [
        "#Image Data Augmentation\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1 )\n",
        "\n",
        "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1)\n",
        "\n",
        "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip= True,zoom_range=.1)\n",
        "\n",
        "#Fitting the augmentation defined above to the data\n",
        "train_generator.fit(x_train)\n",
        "val_generator.fit(x_val)\n",
        "#test_generator.fit(x_test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LxpHXGSb_gc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSW6kSi7b_gd"
      },
      "source": [
        "#Importing library\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5-nsrG9b_gd"
      },
      "source": [
        "np.random.seed(1000)\n",
        "\n",
        "#Instantiation\n",
        "AlexNet = Sequential()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXhcrzf2b_ge"
      },
      "source": [
        "#1st Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=96, input_shape=(28,28,1), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#2nd Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#3rd Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "\n",
        "#4th Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "\n",
        "#5th Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#Passing it to a Fully Connected layer\n",
        "AlexNet.add(Flatten())\n",
        "# 1st Fully Connected Layer\n",
        "AlexNet.add(Dense(4096, input_shape=(28,28,1)))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#2nd Fully Connected Layer\n",
        "AlexNet.add(Dense(4096))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "#Add Dropout\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#3rd Fully Connected Layer\n",
        "AlexNet.add(Dense(1000))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "#Add Dropout\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#Output Layer\n",
        "AlexNet.add(Dense(10))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('softmax'))\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MMnWvP4b_gg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c0b571f-b135-4ff9-964c-f17df55d6b2d"
      },
      "source": [
        "#Model Summary\n",
        "AlexNet.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 7, 7, 96)          11712     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 7, 7, 96)          384       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 7, 7, 96)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 4, 4, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 4, 4, 256)         614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 2, 2, 384)         885120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 2, 2, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 2, 2, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 2, 2, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2, 2, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 2, 2, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                10010     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 10)                40        \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,707,274\n",
            "Trainable params: 25,686,118\n",
            "Non-trainable params: 21,156\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evHEqKnSb_gh"
      },
      "source": [
        "#Learning Rate Annealer\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "lrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5) "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxSEG5Zgb_gh"
      },
      "source": [
        "#Defining the parameters\n",
        "batch_size= 100\n",
        "epochs=60\n",
        "learn_rate=.01"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV9iGcTEb_gi"
      },
      "source": [
        "# Compiling the model\n",
        "AlexNet.compile(loss = keras.losses.categorical_crossentropy, optimizer= 'adam', metrics=['accuracy'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiBxG_9Fb_gi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9d010c1-db23-40b8-b456-c4d73b4fc886"
      },
      "source": [
        "#Training the model\n",
        "history = AlexNet.fit_generator(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs = epochs, steps_per_epoch = x_train.shape[0]//batch_size, validation_data = val_generator.flow(x_val, y_val, batch_size=batch_size), validation_steps = 250, callbacks = [lrr], verbose=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "420/420 [==============================] - ETA: 0s - loss: 0.9207 - accuracy: 0.7292WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 250 batches). You may need to use the repeat() function when building your dataset.\n",
            "420/420 [==============================] - 50s 37ms/step - loss: 0.9203 - accuracy: 0.7293 - val_loss: 1.3135 - val_accuracy: 0.7201\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 2/60\n",
            "420/420 [==============================] - 12s 29ms/step - loss: 0.5634 - accuracy: 0.8332\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 3/60\n",
            "420/420 [==============================] - 12s 29ms/step - loss: 0.4803 - accuracy: 0.8484\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 4/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.4224 - accuracy: 0.8607\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 5/60\n",
            "420/420 [==============================] - 12s 29ms/step - loss: 0.4000 - accuracy: 0.8675\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 6/60\n",
            "420/420 [==============================] - 12s 29ms/step - loss: 0.3789 - accuracy: 0.8725\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 7/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.3638 - accuracy: 0.8765\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 8/60\n",
            "420/420 [==============================] - 12s 29ms/step - loss: 0.3480 - accuracy: 0.8791\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 9/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.3430 - accuracy: 0.8808\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 10/60\n",
            "420/420 [==============================] - 12s 29ms/step - loss: 0.3210 - accuracy: 0.8891\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 11/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.3129 - accuracy: 0.8912\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 12/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.3032 - accuracy: 0.8932\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 13/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.2982 - accuracy: 0.8952\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 14/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.2898 - accuracy: 0.8959\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 15/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.2828 - accuracy: 0.8976\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 16/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.2764 - accuracy: 0.9013\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 17/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.2719 - accuracy: 0.9039\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 18/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.2603 - accuracy: 0.9063\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 19/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.2538 - accuracy: 0.9089\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 20/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.2594 - accuracy: 0.9034\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 21/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.2510 - accuracy: 0.9093\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 22/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.2389 - accuracy: 0.9143\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 23/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.2422 - accuracy: 0.9106\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 24/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.2310 - accuracy: 0.9159\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 25/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.2337 - accuracy: 0.9133\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 26/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.2234 - accuracy: 0.9170\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 27/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.2228 - accuracy: 0.9189\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 28/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.2209 - accuracy: 0.9191\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 29/60\n",
            "420/420 [==============================] - 12s 29ms/step - loss: 0.2166 - accuracy: 0.9196\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 30/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.2156 - accuracy: 0.9213\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 31/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.2015 - accuracy: 0.9255\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 32/60\n",
            "420/420 [==============================] - 12s 29ms/step - loss: 0.1983 - accuracy: 0.9269\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 33/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.2081 - accuracy: 0.9225\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 34/60\n",
            "420/420 [==============================] - 12s 29ms/step - loss: 0.1908 - accuracy: 0.9293\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 35/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.2027 - accuracy: 0.9248\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 36/60\n",
            "420/420 [==============================] - 12s 29ms/step - loss: 0.1857 - accuracy: 0.9319\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 37/60\n",
            "420/420 [==============================] - 12s 29ms/step - loss: 0.1854 - accuracy: 0.9310\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 38/60\n",
            "420/420 [==============================] - 12s 29ms/step - loss: 0.1834 - accuracy: 0.9312\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 39/60\n",
            "420/420 [==============================] - 12s 29ms/step - loss: 0.1822 - accuracy: 0.9335\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 40/60\n",
            "420/420 [==============================] - 12s 29ms/step - loss: 0.1811 - accuracy: 0.9337\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 41/60\n",
            "420/420 [==============================] - 12s 29ms/step - loss: 0.1681 - accuracy: 0.9372\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 42/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.1755 - accuracy: 0.9343\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 43/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.1846 - accuracy: 0.9299\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 44/60\n",
            "420/420 [==============================] - 12s 29ms/step - loss: 0.1693 - accuracy: 0.9371\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 45/60\n",
            "420/420 [==============================] - 12s 29ms/step - loss: 0.1672 - accuracy: 0.9382\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 46/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.1669 - accuracy: 0.9367\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 47/60\n",
            "420/420 [==============================] - 12s 29ms/step - loss: 0.1647 - accuracy: 0.9392\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 48/60\n",
            "420/420 [==============================] - 12s 29ms/step - loss: 0.1589 - accuracy: 0.9407\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 49/60\n",
            "420/420 [==============================] - 12s 29ms/step - loss: 0.1562 - accuracy: 0.9432\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 50/60\n",
            "420/420 [==============================] - 12s 29ms/step - loss: 0.1610 - accuracy: 0.9392\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 51/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.1533 - accuracy: 0.9426\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 52/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.1529 - accuracy: 0.9438\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 53/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.1488 - accuracy: 0.9453\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 54/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.1565 - accuracy: 0.9403\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 55/60\n",
            "420/420 [==============================] - 12s 29ms/step - loss: 0.1475 - accuracy: 0.9450\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 56/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.1483 - accuracy: 0.9462\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 57/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.1476 - accuracy: 0.9447\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 58/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.1428 - accuracy: 0.9459\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 59/60\n",
            "420/420 [==============================] - 12s 28ms/step - loss: 0.1441 - accuracy: 0.9446\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 60/60\n",
            "420/420 [==============================] - 12s 29ms/step - loss: 0.1361 - accuracy: 0.9483\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rLYc5VkvIPX",
        "outputId": "6b29de56-8fc3-4243-d0cf-03e2b6bfa51a"
      },
      "source": [
        "loss,acc = AlexNet.evaluate(x_val,y_val)\r\n",
        "print(\"Accuracy: %.3f\" %acc)\r\n",
        "print(\"Loss: %.3f\" %loss)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "563/563 [==============================] - 3s 5ms/step - loss: 0.4157 - accuracy: 0.8673\n",
            "Accuracy: 0.867\n",
            "Loss: 0.416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzE9cLTzuGbD"
      },
      "source": [
        "In this model Implementation of fashion_mnist using AlexNet architecture is done.\r\n",
        "Libraries used for implementation are:\r\n",
        "Keras, tensorflow, ImageDataGenerator.\r\n",
        "\r\n",
        "Some layers used: Dense,Flatten,Convolution2D,Dropout,MaxPooling.\r\n",
        "\r\n",
        "Parameters: Strides, KernelSize, Input size, activation functions, hidden layers, number of neurons, dimensions.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "Observation:\r\n",
        "\r\n",
        "Train Accuracy: 94.83%\r\n",
        "\r\n",
        "Loss : 0.1361\r\n",
        "\r\n",
        "\r\n",
        "Test Accuracy: 86.73%\r\n",
        "\r\n",
        "Loss: 0.416"
      ]
    }
  ]
}